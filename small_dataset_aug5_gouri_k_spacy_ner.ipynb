{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "small_dataset_aug5_gouri_k_spacy_ner.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN5XaKCCUfk1uDXfdh5nFO6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/csml1020gk/csml1030-capstone-project/blob/main/small_dataset_aug5_gouri_k_spacy_ner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnc2TVu5WgjZ"
      },
      "source": [
        "In this notebook, I will be working with a small text  dataset ( page 1 of a pdf ) to extract a term from the text and save it's span and label as a line in the training data file.\n",
        "\n",
        "Once this model works, we can try to generalize it to work over text extracted from several pages within the same PDF.\n",
        "\n",
        "We can then try to scale it up to work with\n",
        "\n",
        "1. 1 entire pdf \n",
        "2. all pdfs   \n",
        "\n",
        "At the end, we will develop a baseline model to predict the entity on  a test PDF \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CL5bdkDAW9cJ",
        "outputId": "bdd21516-50ed-442e-d20d-89e10c675b4d"
      },
      "source": [
        "#installations\n",
        "!pip install spacy\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.2.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (4.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.5.30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxcwUHx61pN5",
        "outputId": "f85b81c0-d3b6-4bed-e83d-4dfeae95e135"
      },
      "source": [
        "#download language models \n",
        "!python -m spacy download en_core_web_sm\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "#working with a larger model can be slower but can impact accuracy "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 27.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.2.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.5.30)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeXDDXZbXbSq",
        "outputId": "3aa5d460-eb38-4ea3-ff16-fc7bd7f3d59b"
      },
      "source": [
        "#mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "844neArFXX66"
      },
      "source": [
        "#imports\n",
        "import os \n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "import json\n",
        "from spacy.matcher import Matcher, PhraseMatcher\n",
        "from spacy.lang.en import English\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLj4tPxfdAsu"
      },
      "source": [
        "#functions\n",
        "def listToString(s): \n",
        "    # initialize an empty string\n",
        "    str1 = \"\" \n",
        "    # traverse in the string  \n",
        "    for ele in s: \n",
        "      str1 += ele\n",
        "    # return string  \n",
        "    return str1 \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-n358tEEYg9n",
        "outputId": "41d75423-6a3a-4a34-a622-839bacf68402"
      },
      "source": [
        "#os\n",
        "base_path = '/content/drive/MyDrive/week4'\n",
        "save_path = '/content/drive/MyDrive/week4'\n",
        "os.chdir(base_path)\n",
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/week4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTeEA4svYn93",
        "outputId": "5b348cf5-4e44-453c-fbd2-8306abb672a3"
      },
      "source": [
        "os.listdir()\n",
        "file_text = open(os.path.join(base_path, 'small_dataset.txt'),\"r\")\n",
        "file_list = file_text.readlines()\n",
        "file_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['text\\n',\n",
              " '0\\n',\n",
              " \"WELL CANADA LTD.Corporate lnformation Summaryas at November 25,2013Law Firm:Siskinds LLPTel5',t9 672-212'.1Fax519 672-9296Personnel:Graeme SperrynJennifer A. BoltonsolicitorclerkLAW FIRM INFORMATIONFile No.:840423Record No.:840423Accountinq No.:840423File Opening Date:November 6, 2013French Name:Date of lncorporation:November 4,2013Leqal Structure:Private CorporationJurisdiction:OntarioOntario Corporation No.:2394556Nature of Business:Contract Siqnins Authoritv:Unanimous Shareholder Aqreement:N/yAny Other Shareholder Aqreement:N/vTrade nameGENERAL INFORMATIONlsactive?Y/nKeep annua! resolutions current?Y/nLast an nual meeting/resolutionsAre signatures outstanding?N/vMinute Book- held by law firm?Y/nMinute Book- box number:Minute BookIY/nSTATUS AND RECORDS\\n\",\n",
              " '\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNBwb--Pfkiq"
      },
      "source": [
        "#convert list to dataframe \n",
        "\n",
        "df_extracted_pages = DataFrame(file_list, columns =['text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "3xYprVQ7HeK9",
        "outputId": "c460f409-2d66-4a14-f276-9d8ddd7f30e7"
      },
      "source": [
        "df_extracted_pages\n",
        "#One page looks like this \n",
        "#row 0 - text \n",
        "#row1 - \\n\n",
        "#row2 - the page text as a string\n",
        "#row 3 - \\n \n",
        "#every page in our complete extracted text would follow this format\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>text\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WELL CANADA LTD.Corporate lnformation Summarya...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0                                             text\\n\n",
              "1                                                0\\n\n",
              "2  WELL CANADA LTD.Corporate lnformation Summarya...\n",
              "3                                                 \\n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "KADfrlcfIR7V",
        "outputId": "19fc79c8-88f6-4d41-b62b-c51508ac5b0b"
      },
      "source": [
        "df_extracted_pages['text'][2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"WELL CANADA LTD.Corporate lnformation Summaryas at November 25,2013Law Firm:Siskinds LLPTel5',t9 672-212'.1Fax519 672-9296Personnel:Graeme SperrynJennifer A. BoltonsolicitorclerkLAW FIRM INFORMATIONFile No.:840423Record No.:840423Accountinq No.:840423File Opening Date:November 6, 2013French Name:Date of lncorporation:November 4,2013Leqal Structure:Private CorporationJurisdiction:OntarioOntario Corporation No.:2394556Nature of Business:Contract Siqnins Authoritv:Unanimous Shareholder Aqreement:N/yAny Other Shareholder Aqreement:N/vTrade nameGENERAL INFORMATIONlsactive?Y/nKeep annua! resolutions current?Y/nLast an nual meeting/resolutionsAre signatures outstanding?N/vMinute Book- held by law firm?Y/nMinute Book- box number:Minute BookIY/nSTATUS AND RECORDS\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0cM7Ttlf2N6"
      },
      "source": [
        "#dataframe to txt\n",
        "#get the filename minus extension\n",
        "df_extracted_pages.to_csv(os.path.join(save_path, \"small_data.txt\"), sep ='\\n')\n",
        "#this is a text file and can be opened with google docs \n",
        "#the extension is .pdf, but not to confuse , it is a text file \n",
        "#pages are numbered \n",
        "#can be renamed \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-wnanR42QsR"
      },
      "source": [
        "#create a processed Doc object for the document.\n",
        "#input is the text file \n",
        "file_name = os.path.join(save_path, \"small_data.txt\")\n",
        "file_text = open(file_name).read()\n",
        "file_doc = nlp(file_text)\n",
        "#the text file is converted into a processed doc file "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwO2Yc_WyVtd"
      },
      "source": [
        "Statistical analysis - visualizations will be prepared on the full text. not here \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woQC6wqg_-0Q",
        "outputId": "aac7046e-3e3a-478b-db2e-abb200eba734"
      },
      "source": [
        "#tokenization - identify basic units \n",
        "for token in file_doc:\n",
        "  print (token, token.idx)\n",
        "#preserves the starting index of the tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 0\n",
            "text 1\n",
            "\n",
            " 5\n",
            "0 6\n",
            "\n",
            " 7\n",
            "\" 8\n",
            "text 9\n",
            "\n",
            " 13\n",
            "\" 14\n",
            "\n",
            " 15\n",
            "1 16\n",
            "\n",
            " 17\n",
            "\" 18\n",
            "0 19\n",
            "\n",
            " 20\n",
            "\" 21\n",
            "\n",
            " 22\n",
            "2 23\n",
            "\n",
            " 24\n",
            "\" 25\n",
            "WELL 26\n",
            "CANADA 31\n",
            "LTD.Corporate 38\n",
            "lnformation 52\n",
            "Summaryas 64\n",
            "at 74\n",
            "November 77\n",
            "25,2013Law 86\n",
            "Firm 97\n",
            ": 101\n",
            "Siskinds 102\n",
            "LLPTel5',t9 111\n",
            "672 123\n",
            "- 126\n",
            "212'.1Fax519 127\n",
            "672 140\n",
            "- 143\n",
            "9296Personnel 144\n",
            ": 157\n",
            "Graeme 158\n",
            "SperrynJennifer 165\n",
            "A. 181\n",
            "BoltonsolicitorclerkLAW 184\n",
            "FIRM 208\n",
            "INFORMATIONFile 213\n",
            "No.:840423Record 229\n",
            "No.:840423Accountinq 246\n",
            "No.:840423File 267\n",
            "Opening 282\n",
            "Date 290\n",
            ": 294\n",
            "November 295\n",
            "6 304\n",
            ", 305\n",
            "2013French 307\n",
            "Name 318\n",
            ": 322\n",
            "Date 323\n",
            "of 328\n",
            "lncorporation 331\n",
            ": 344\n",
            "November 345\n",
            "4,2013Leqal 354\n",
            "Structure 366\n",
            ": 375\n",
            "Private 376\n",
            "CorporationJurisdiction 384\n",
            ": 407\n",
            "OntarioOntario 408\n",
            "Corporation 423\n",
            "No.:2394556Nature 435\n",
            "of 453\n",
            "Business 456\n",
            ": 464\n",
            "Contract 465\n",
            "Siqnins 474\n",
            "Authoritv 482\n",
            ": 491\n",
            "Unanimous 492\n",
            "Shareholder 502\n",
            "Aqreement 514\n",
            ": 523\n",
            "N 524\n",
            "/ 525\n",
            "yAny 526\n",
            "Other 531\n",
            "Shareholder 537\n",
            "Aqreement 549\n",
            ": 558\n",
            "N 559\n",
            "/ 560\n",
            "vTrade 561\n",
            "nameGENERAL 568\n",
            "INFORMATIONlsactive?Y 580\n",
            "/ 601\n",
            "nKeep 602\n",
            "annua 608\n",
            "! 613\n",
            "resolutions 615\n",
            "current?Y 627\n",
            "/ 636\n",
            "nLast 637\n",
            "an 643\n",
            "nual 646\n",
            "meeting 651\n",
            "/ 658\n",
            "resolutionsAre 659\n",
            "signatures 674\n",
            "outstanding?N 685\n",
            "/ 698\n",
            "vMinute 699\n",
            "Book- 707\n",
            "held 713\n",
            "by 718\n",
            "law 721\n",
            "firm?Y 725\n",
            "/ 731\n",
            "nMinute 732\n",
            "Book- 740\n",
            "box 746\n",
            "number 750\n",
            ": 756\n",
            "Minute 757\n",
            "BookIY 764\n",
            "/ 770\n",
            "nSTATUS 771\n",
            "AND 779\n",
            "RECORDS 783\n",
            "\n",
            " 790\n",
            "\" 791\n",
            "\n",
            " 792\n",
            "3 793\n",
            "\n",
            " 794\n",
            "\" 795\n",
            "\n",
            " 796\n",
            "\" 797\n",
            "\n",
            " 798\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChDe6PKxBc9W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdf99ad5-b00b-4d38-b9a0-d16851e8e07c"
      },
      "source": [
        "#attributes of each token\n",
        "for token in file_doc:\n",
        "  print (token, token.idx, token.text_with_ws,\n",
        "    token.is_alpha, token.is_punct, token.is_space,\n",
        "      token.shape_, token.is_stop)\n",
        "#the tokenizer can be customized to our use case "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 0 \n",
            " False False True \n",
            " False\n",
            "text 1 text True False False xxxx False\n",
            "\n",
            " 5 \n",
            " False False True \n",
            " False\n",
            "0 6 0 False False False d False\n",
            "\n",
            " 7 \n",
            " False False True \n",
            " False\n",
            "\" 8 \" False True False \" False\n",
            "text 9 text True False False xxxx False\n",
            "\n",
            " 13 \n",
            " False False True \n",
            " False\n",
            "\" 14 \" False True False \" False\n",
            "\n",
            " 15 \n",
            " False False True \n",
            " False\n",
            "1 16 1 False False False d False\n",
            "\n",
            " 17 \n",
            " False False True \n",
            " False\n",
            "\" 18 \" False True False \" False\n",
            "0 19 0 False False False d False\n",
            "\n",
            " 20 \n",
            " False False True \n",
            " False\n",
            "\" 21 \" False True False \" False\n",
            "\n",
            " 22 \n",
            " False False True \n",
            " False\n",
            "2 23 2 False False False d False\n",
            "\n",
            " 24 \n",
            " False False True \n",
            " False\n",
            "\" 25 \" False True False \" False\n",
            "WELL 26 WELL  True False False XXXX True\n",
            "CANADA 31 CANADA  True False False XXXX False\n",
            "LTD.Corporate 38 LTD.Corporate  False False False XXX.Xxxxx False\n",
            "lnformation 52 lnformation  True False False xxxx False\n",
            "Summaryas 64 Summaryas  True False False Xxxxx False\n",
            "at 74 at  True False False xx True\n",
            "November 77 November  True False False Xxxxx False\n",
            "25,2013Law 86 25,2013Law  False False False dd,ddddXxx False\n",
            "Firm 97 Firm True False False Xxxx False\n",
            ": 101 : False True False : False\n",
            "Siskinds 102 Siskinds  True False False Xxxxx False\n",
            "LLPTel5',t9 111 LLPTel5',t9  False False False XXXXxxd',xd False\n",
            "672 123 672 False False False ddd False\n",
            "- 126 - False True False - False\n",
            "212'.1Fax519 127 212'.1Fax519  False False False ddd'.dXxxddd False\n",
            "672 140 672 False False False ddd False\n",
            "- 143 - False True False - False\n",
            "9296Personnel 144 9296Personnel False False False ddddXxxxx False\n",
            ": 157 : False True False : False\n",
            "Graeme 158 Graeme  True False False Xxxxx False\n",
            "SperrynJennifer 165 SperrynJennifer  True False False XxxxxXxxxx False\n",
            "A. 181 A.  False False False X. False\n",
            "BoltonsolicitorclerkLAW 184 BoltonsolicitorclerkLAW  True False False XxxxxXXX False\n",
            "FIRM 208 FIRM  True False False XXXX False\n",
            "INFORMATIONFile 213 INFORMATIONFile  True False False XXXXxxx False\n",
            "No.:840423Record 229 No.:840423Record  False False False Xx.:ddddXxxxx False\n",
            "No.:840423Accountinq 246 No.:840423Accountinq  False False False Xx.:ddddXxxxx False\n",
            "No.:840423File 267 No.:840423File  False False False Xx.:ddddXxxx False\n",
            "Opening 282 Opening  True False False Xxxxx False\n",
            "Date 290 Date True False False Xxxx False\n",
            ": 294 : False True False : False\n",
            "November 295 November  True False False Xxxxx False\n",
            "6 304 6 False False False d False\n",
            ", 305 ,  False True False , False\n",
            "2013French 307 2013French  False False False ddddXxxxx False\n",
            "Name 318 Name True False False Xxxx True\n",
            ": 322 : False True False : False\n",
            "Date 323 Date  True False False Xxxx False\n",
            "of 328 of  True False False xx True\n",
            "lncorporation 331 lncorporation True False False xxxx False\n",
            ": 344 : False True False : False\n",
            "November 345 November  True False False Xxxxx False\n",
            "4,2013Leqal 354 4,2013Leqal  False False False d,ddddXxxxx False\n",
            "Structure 366 Structure True False False Xxxxx False\n",
            ": 375 : False True False : False\n",
            "Private 376 Private  True False False Xxxxx False\n",
            "CorporationJurisdiction 384 CorporationJurisdiction True False False XxxxxXxxxx False\n",
            ": 407 : False True False : False\n",
            "OntarioOntario 408 OntarioOntario  True False False XxxxxXxxxx False\n",
            "Corporation 423 Corporation  True False False Xxxxx False\n",
            "No.:2394556Nature 435 No.:2394556Nature  False False False Xx.:ddddXxxxx False\n",
            "of 453 of  True False False xx True\n",
            "Business 456 Business True False False Xxxxx False\n",
            ": 464 : False True False : False\n",
            "Contract 465 Contract  True False False Xxxxx False\n",
            "Siqnins 474 Siqnins  True False False Xxxxx False\n",
            "Authoritv 482 Authoritv True False False Xxxxx False\n",
            ": 491 : False True False : False\n",
            "Unanimous 492 Unanimous  True False False Xxxxx False\n",
            "Shareholder 502 Shareholder  True False False Xxxxx False\n",
            "Aqreement 514 Aqreement True False False Xxxxx False\n",
            ": 523 : False True False : False\n",
            "N 524 N True False False X False\n",
            "/ 525 / False True False / False\n",
            "yAny 526 yAny  True False False xXxx False\n",
            "Other 531 Other  True False False Xxxxx True\n",
            "Shareholder 537 Shareholder  True False False Xxxxx False\n",
            "Aqreement 549 Aqreement True False False Xxxxx False\n",
            ": 558 : False True False : False\n",
            "N 559 N True False False X False\n",
            "/ 560 / False True False / False\n",
            "vTrade 561 vTrade  True False False xXxxxx False\n",
            "nameGENERAL 568 nameGENERAL  True False False xxxxXXXX False\n",
            "INFORMATIONlsactive?Y 580 INFORMATIONlsactive?Y False False False XXXXxxxx?X False\n",
            "/ 601 / False True False / False\n",
            "nKeep 602 nKeep  True False False xXxxx False\n",
            "annua 608 annua True False False xxxx False\n",
            "! 613 !  False True False ! False\n",
            "resolutions 615 resolutions  True False False xxxx False\n",
            "current?Y 627 current?Y False False False xxxx?X False\n",
            "/ 636 / False True False / False\n",
            "nLast 637 nLast  True False False xXxxx False\n",
            "an 643 an  True False False xx True\n",
            "nual 646 nual  True False False xxxx False\n",
            "meeting 651 meeting True False False xxxx False\n",
            "/ 658 / False True False / False\n",
            "resolutionsAre 659 resolutionsAre  True False False xxxxXxx False\n",
            "signatures 674 signatures  True False False xxxx False\n",
            "outstanding?N 685 outstanding?N False False False xxxx?X False\n",
            "/ 698 / False True False / False\n",
            "vMinute 699 vMinute  True False False xXxxxx False\n",
            "Book- 707 Book-  False False False Xxxx- False\n",
            "held 713 held  True False False xxxx False\n",
            "by 718 by  True False False xx True\n",
            "law 721 law  True False False xxx False\n",
            "firm?Y 725 firm?Y False False False xxxx?X False\n",
            "/ 731 / False True False / False\n",
            "nMinute 732 nMinute  True False False xXxxxx False\n",
            "Book- 740 Book-  False False False Xxxx- False\n",
            "box 746 box  True False False xxx False\n",
            "number 750 number True False False xxxx False\n",
            ": 756 : False True False : False\n",
            "Minute 757 Minute  True False False Xxxxx False\n",
            "BookIY 764 BookIY True False False XxxxXX False\n",
            "/ 770 / False True False / False\n",
            "nSTATUS 771 nSTATUS  True False False xXXXX False\n",
            "AND 779 AND  True False False XXX True\n",
            "RECORDS 783 RECORDS True False False XXXX False\n",
            "\n",
            " 790 \n",
            " False False True \n",
            " False\n",
            "\" 791 \" False True False \" False\n",
            "\n",
            " 792 \n",
            " False False True \n",
            " False\n",
            "3 793 3 False False False d False\n",
            "\n",
            " 794 \n",
            " False False True \n",
            " False\n",
            "\" 795 \" False True False \" False\n",
            "\n",
            " 796 \n",
            " False False True \n",
            " False\n",
            "\" 797 \" False True False \" False\n",
            "\n",
            " 798 \n",
            " False False True \n",
            " False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NAITXmaCjyF",
        "outputId": "e435e18f-1840-43cc-9bc0-6fa8aa068034"
      },
      "source": [
        "#statistical analysis \n",
        "from collections import Counter\n",
        "words = [token.text for token in file_doc\n",
        "  if not token.is_stop and not token.is_punct]\n",
        "word_freq = Counter(words)\n",
        "common_words = word_freq.most_common(5)\n",
        "print (common_words)\n",
        "unique_words = [word for (word, freq) in word_freq.items() if freq == 1]\n",
        "print (unique_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('\\n', 14), ('November', 3), ('text', 2), ('0', 2), ('672', 2)]\n",
            "['1', '2', 'CANADA', 'LTD.Corporate', 'lnformation', 'Summaryas', '25,2013Law', 'Firm', 'Siskinds', \"LLPTel5',t9\", \"212'.1Fax519\", '9296Personnel', 'Graeme', 'SperrynJennifer', 'A.', 'BoltonsolicitorclerkLAW', 'FIRM', 'INFORMATIONFile', 'No.:840423Record', 'No.:840423Accountinq', 'No.:840423File', 'Opening', '6', '2013French', 'lncorporation', '4,2013Leqal', 'Structure', 'Private', 'CorporationJurisdiction', 'OntarioOntario', 'Corporation', 'No.:2394556Nature', 'Business', 'Contract', 'Siqnins', 'Authoritv', 'Unanimous', 'yAny', 'vTrade', 'nameGENERAL', 'INFORMATIONlsactive?Y', 'nKeep', 'annua', 'resolutions', 'current?Y', 'nLast', 'nual', 'meeting', 'resolutionsAre', 'signatures', 'outstanding?N', 'vMinute', 'held', 'law', 'firm?Y', 'nMinute', 'box', 'number', 'Minute', 'BookIY', 'nSTATUS', 'RECORDS', '3']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i50aOR40Ldn8"
      },
      "source": [
        "#create the training data to teach the named entity model\n",
        "#TEXTS is a list of sentences in the page \n",
        "#find all mentions of WELL CANADA LTD. so we can create training data to teach a model to recognize them as COM \n",
        "#write a pattern which matches  WELL CANADA LTD. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#file_name = os.path.join(save_path, \"small_data.txt\")\n",
        "#TEXTS = open(file_name).read()\n",
        "#matcher = PhraseMatcher(nlp.vocab, attr = \"LOWER\")\n",
        "\n",
        "# Token which matches WELL CANADA LTD.\n",
        "#pattern = [{\"TEXT\": \"WELL CANADA LTD.\"}]\n",
        "\n",
        "# Add patterns to the matcher and check the result\n",
        "#matcher.add(\"COM\", None, pattern)\n",
        "#for doc in nlp.pipe(TEXTS):\n",
        "#    print([doc[start:end] for match_id, start, end in matcher(doc)])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import spacy\n",
        "from spacy.matcher import PhraseMatcher\n",
        "corpus = df_extracted_pages['text'][2]#string \n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(corpus)\n",
        "matcher = PhraseMatcher(nlp.vocab)\n",
        "terms = [\"WELL CANADA\"]#term to match \n",
        "\n",
        "train_data = open(os.path.join(save_path, '/content/drive/MyDrive/week4/ent.csv'), 'w')\n",
        "# Only run nlp.make_doc to speed things up\n",
        "patterns = [nlp.make_doc(text) for text in terms]\n",
        "matcher.add(\"TerminologyList\", patterns)#add the pattern to the matcher object \n",
        "\n",
        "matches = matcher(doc)\n",
        "annotations = []#saved list of annotations, one in this case \n",
        "list_str = \"(\"\n",
        "for match_id, start, end in matches:\n",
        "    span = doc[start:end]\n",
        "    #list_str = span.text + \",\" + str(start) + \",\" +  str(end) + \"\\n\"\n",
        "    annotations.append((span.text, {'entities': [(start, end, 'COM')]}))\n",
        "    annotations_str = str(annotations) + \"\\n\"\n",
        "    #write to file \n",
        "    train_data.write(str(annotations_str))\n",
        "train_data.close()\n",
        "#training data is in spacy format "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oE07zQcCbl8J",
        "outputId": "62fb319f-a544-4df0-f33e-5f7e77a427f6"
      },
      "source": [
        "print(annotations)\n",
        "#WELL CANADA appears only once in this document , at the beginning "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('WELL CANADA', {'entities': [(0, 2, 'COM')]})]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OO1vGofCI98q"
      },
      "source": [
        "from __future__ import unicode_literals, print_function\n",
        "import plac\n",
        "import random\n",
        "from pathlib import Path\n",
        "import spacy\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_9EexzUJB5_"
      },
      "source": [
        "#create your custom entity data for the input text where the named entity is to be identified by the model during the testing period\n",
        "\n",
        "TRAIN_DATA = annotations"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYsjCLdQKLSy"
      },
      "source": [
        "#define the variables required for the training model\n",
        "model = None\n",
        "output_dir=Path(save_path)\n",
        "n_iter=10\n",
        "#to save time,  only tried ten iterations "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RahVt8f3KhQ3",
        "outputId": "81a8f100-5113-4d0a-978b-adb685607e21"
      },
      "source": [
        "#load a blank model for the process to carry out the NER action and set up the pipeline with only NER using create_pipe function\n",
        "#load the model\n",
        "\n",
        "if model is not None:\n",
        "    nlp = spacy.load(model)  \n",
        "    print(\"Loaded model '%s'\" % model)\n",
        "else:\n",
        "    nlp = spacy.blank('en')  \n",
        "    print(\"Created blank 'en' model\")\n",
        "\n",
        "#set up the pipeline\n",
        "\n",
        "if 'ner' not in nlp.pipe_names:\n",
        "    ner = nlp.create_pipe('ner')\n",
        "    nlp.add_pipe(ner, last=True)\n",
        "else:\n",
        "    ner = nlp.get_pipe('ner')\n",
        "\n",
        "#the pipleline can be expanded later to include other steps \n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Created blank 'en' model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I52OrnbUK1QD",
        "outputId": "cb7da410-5036-46a2-f551-f62ab670987e"
      },
      "source": [
        "for _, ann in TRAIN_DATA:\n",
        "    for ent in ann.get('entities'):# we  only have one entity \n",
        "        ner.add_label(ent[2])\n",
        "\n",
        "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
        "with nlp.disable_pipes(*other_pipes):  # only train NER\n",
        "    optimizer = nlp.begin_training()\n",
        "    for itn in range(n_iter):\n",
        "        random.shuffle(TRAIN_DATA)\n",
        "        losses = {}\n",
        "        for text, annotations in tqdm(TRAIN_DATA):\n",
        "            nlp.update(\n",
        "                [text],  \n",
        "                [annotations],  \n",
        "                drop=0.5,  \n",
        "                sgd=optimizer,\n",
        "                losses=losses)\n",
        "        print(losses)\n",
        "    #in ten interations, the loss comes down to 68%\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 22.66it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 40.44it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 39.93it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 36.58it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 43.40it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 36.34it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 40.29it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'ner': 1.0000000447034836}\n",
            "{'ner': 0.9551979899406433}\n",
            "{'ner': 0.9488962888717651}\n",
            "{'ner': 0.8623597919940948}\n",
            "{'ner': 0.8236702084541321}\n",
            "{'ner': 0.7574411556124687}\n",
            "{'ner': 0.6925287395715714}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 37.52it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 31.67it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 40.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'ner': 0.6846142262220383}\n",
            "{'ner': 0.6839388981461525}\n",
            "{'ner': 0.6845945939421654}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSUqLWH4OsWb",
        "outputId": "f1e1c0a3-cce9-431b-b752-bffeac7a3eff"
      },
      "source": [
        "if output_dir is not None:\n",
        "    output_dir = Path(output_dir)\n",
        "    if not output_dir.exists():\n",
        "        output_dir.mkdir()\n",
        "    nlp.to_disk(os.path.join(output_dir, 'nlp_model'))\n",
        "    print(\"Saved model to\", output_dir)\n",
        "\n",
        "#save the model "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to /content/drive/MyDrive/week4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvtJ1HtLPNl6"
      },
      "source": [
        "\n",
        "try_model = spacy.load(os.path.join(output_dir, 'nlp_model'))#load the  trained model "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhjKN3H0P4m-",
        "outputId": "6bbddf7b-362e-4dc8-9ec5-78a1c924608e"
      },
      "source": [
        "try_model.entity.labels#our model can only predict COM labels at the moment "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('COM',)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDryZsqhf5k_"
      },
      "source": [
        "#input text file as string \n",
        "test_file = open(os.path.join(base_path, \"test_data.txt\"), \"r\")\n",
        "file_str = listToString(test_file.readlines())\n",
        "\n",
        "test_doc = try_model(file_str)\n",
        "\n",
        "#print(test_doc)\n",
        "for ent in test_doc.ents:\n",
        "  print(f'{ent.label_:{20}} - {ent.text}')\n",
        "#the ner model could not find any entities becuse of the large losses. we have very small training data too "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0RaywE75twf"
      },
      "source": [
        "# The training data must have many examples in order to generate a good ner model that can predict entities from test data. "
      ]
    }
  ]
}